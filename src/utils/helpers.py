import numpy as np
import os
import matplotlib.pyplot as plt
import cv2
from skimage.measure import label


DATA_DIR = os.getenv('BLACKHOLE')
PATHS = {
    'root': DATA_DIR,
    'train': f"{DATA_DIR}/train_v2",
    'test': f"{DATA_DIR}/test_v2",
}


#################### RUN LENGTH ENCODING #################### 

def rle_decode(mask_rle, shape=(768, 768)):
    '''
    From https://www.kaggle.com/paulorzp/run-length-encode-and-decode    

    :param mask_rle: run-length as string formated (start length)
    :param shape: (height,width) of array to return 

    :returns: numpy array, 1 - mask, 0 - background
    '''

    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape).T  # Needed to align to RLE direction


def rle_encode(img):
    '''
    img: numpy array, 1 - mask, 0 - background
    Returns run length as string formated
    '''
    pixels = img.flatten()
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)


def multi_rle_encode(img):
    labels = label(img)
    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]


def masks_as_image(rle_masks, shape = (768, 768)):
    """
    Convert masks from list (run-length encoded) to image

    :param rle_masks: An array of strings (where each string is the run-length encoded mask)
    """

    # Take the individual ship masks and create a single mask array for all ships
    all_masks = np.zeros(shape, dtype=np.int16)

    for mask in rle_masks:
        if isinstance(mask, str):
            all_masks += rle_decode(mask)

    return np.expand_dims(all_masks, -1)


def rle2bbox(rle: str, shape = (768,768)):
    """
    Converts RLE to bound-box coordinates [xc, yc, h, w]

    :param rle: The run length encoding
    :param shape: The shape of the image
    """

    a = np.fromiter(rle.split(), dtype=np.uint)
    a = a.reshape((-1, 2))
    a[:,0] -= 1
    
    y0 = a[:,0] % shape[0]
    y1 = y0 + a[:,1]
    if np.any(y1 > shape[0]):
        y0 = 0
        y1 = shape[0]
    else:
        y0 = np.min(y0)
        y1 = np.max(y1)
    
    x0 = a[:,0] // shape[0]
    x1 = (a[:,0] + a[:,1]) // shape[0]
    x0 = np.min(x0)
    x1 = np.max(x1)
    
    if x1 > shape[1]:
        raise ValueError("invalid RLE or image dimensions: x1=%d > shape[1]=%d" % (
            x1, shape[1]
        ))

    xc = (x0+x1)/(2*shape[0])
    yc = (y0+y1)/(2*shape[0])
    w = np.abs(x1-x0)/shape[0]
    h = np.abs(y1-y0)/shape[0]
    return [xc, yc, h, w]


#################### PLOTTING OR VIEWING IMAGES #################### 

def mask_overlay(image, mask, color=(0, 1, 0)):
    """
    Helper function to visualize mask on the top of the image
    """

    mask = np.dstack((mask, mask, mask)) * np.array(color)
    weighted_sum = cv2.addWeighted(mask, 0.5, image, 0.5, 0.)
    img = image.copy()
    ind = mask[:, :, 1] > 0
    img[ind] = weighted_sum[ind]    
    return img


def get_image_from_tensor_and_masks(tensor, masks):
    # Rearrange the dimensions from [channels, height, width] to [height, width, channels], as matplotlib expects this format.
    tensor = tensor.numpy().transpose((1, 2, 0))

    # Undo the normalization to bring pixel values back to a visible range
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    tensor = std * tensor + mean
    # Ensures pixel values are in the range [0, 1]
    tensor = np.clip(tensor, 0, 1)

    # Same as above: converts to [height, width, channels] and ensures range of [0, 1]
    res_masks = []
    for mask in masks:
        mask = mask.numpy().transpose((1, 2, 0))
        mask = np.clip(mask, 0, 1)
        res_masks.append(mask)
    
    return tensor, res_masks


def imshow_tensor_with_mask(img, mask, title=None):
    """
    Imshow for Tensor.
    """
    img, [mask] = get_image_from_tensor_and_masks(img, [mask])

    plt.imshow(mask_overlay(img, mask))
    if title is not None:
        plt.title(title)
    plt.pause(0.001) 


def compare_model_outputs_with_ground_truths(images, gt_masks, out_masks):
    """
    Compare a series of images with the mask generated by the UNet with the ground-truth mask
    """

    gt_overlays = []
    out_overlays = []

    for img, gt, out in zip(images, gt_masks, out_masks):
        # Convert to image
        img, [gt, out] = get_image_from_tensor_and_masks(img, [gt, out])

        # Overlay image with masks
        gt_overlay = mask_overlay(img, gt)
        out_overlay = mask_overlay(img, out)

        gt_overlays.append(gt_overlay)
        out_overlays.append(out_overlay)

    assert len(gt_overlays) == len(out_overlays)

    # Plot the two arrays in two columns
    n = len(gt_overlays)
    _, axes = plt.subplots(n, 2, figsize=(10, 5 * n))
    axes[0, 0].set_title("Model output", fontsize=24, pad=20)
    axes[0, 1].set_title("Ground truth", fontsize=24, pad=20)
    
    for i in range(n):
        # Plotting the model output in the left column
        axes[i, 0].imshow(out_overlays[i])
        axes[i, 0].axis('off')
        
        # Plotting the ground truths in the right column
        axes[i, 1].imshow(gt_overlays[i])
        axes[i, 1].axis('off')
    
    plt.tight_layout(rect=[0, 0, 1, 0.995])



def draw_bboxes_on_image(image: np.ndarray, boxes: list, confidence_score_threshold = 0.0, show_confidence_scores = True):
    """
    Draw bounding boxes on the given images

    :param image: The image to draw on (numpy array)
    :param boxes: a list of boxes in the format [class_pred, confidence_score, x, y, w, h]
    """
    for box in boxes:
        if box[1] <= confidence_score_threshold:
            continue

        x,y,w,h = box[2], box[3], box[4], box[5]
        img_size = image.shape[0]

        Xmin  = int((x - w/2) * img_size)
        Ymin  = int((y - h/2) * img_size)
        Xmax  = int((x + w/2) * img_size)
        Ymax  = int((y + h/2) * img_size)

        ### Draw box ###
        cv2.rectangle(image, (Xmin,Ymin), (Xmax,Ymax), (255,0,0), thickness = 2)

        ### Draw confidence score next to the box ###
        if show_confidence_scores:
            label = f"{box[1]:.2f}"
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]
            text_w, text_h = text_size[0], text_size[1]
            img_h, img_w = image.shape[:2]
            # Adjust text position if it goes out of bounds
            text_x = max(0, min(Xmin, img_w - text_w))  # Clamp X within [0, img_w - text_w]
            text_y = max(0, min(Ymax + text_h + 10, img_h))  # Clamp Y within [0, img_h]
            # Draw text
            cv2.putText(image, label, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), thickness=2)
